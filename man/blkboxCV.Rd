% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/BlackBoxCV.R
\name{blkboxCV}
\alias{blkboxCV}
\title{k-fold cross validation with blkbox}
\usage{
blkboxCV(data, labels, folds, seeds, ntrees, mTry, repeats, Kernel, Gamma,
  exclude, Method, AUC)
}
\arguments{
\item{data}{A data.frame where the columns correspond to features and the rows are samples. The dataframe will be shuffled and split into k folds for downstream analysis.}

\item{labels}{A character or numeric vector of the class indetifiers that each sample belongs.}

\item{folds}{The number of times the data set will be subsectioned (number of samples / k, if modulo exists the groups will be as close to the same size as possible). Each data subsection will be used as a holdout portion. Default = 10.}

\item{seeds}{A numeric vector}

\item{ntrees}{The number of trees used in the ensemble based learners (randomforest, bigrf, party, bartmachine). default = 500.}

\item{mTry}{The number of features sampled at each node in the trees of ensemble based learners (randomforest, bigrf, party, bartmachine). default = sqrt(number of features).}

\item{repeats}{repeat the cross validation process}

\item{Kernel}{The type of kernel used in the support vector machine algorithm (linear, radial, sigmoid, polynomial). default = "linear".}

\item{Gamma}{Advanced parameter, defines the distance of which a single training example reaches. Low gamma will produce a SVM with softer boundries, as Gamma increases the boundries will eventually become restricted to their singular support vector.}

\item{exclude}{removes certain algorithms from analysis - to exclude random forest which you would set exclude = c(1). To only run GLM you would set exclude = c(1:4,6:8). The algorithms each have their own numeric identifier. randomforest = 1, knn = 2, bartmachine = 3, party = 4, glm = 5, pam = 6, nnet = 7, svm = 8.}

\item{Method}{The algorithm used to feature select the data. Uses the feature importance from the algorithms to rank and remove anything below the AUC threshold.}

\item{AUC}{Area under the curve selection measure. The relative importance of features is calculated and then ranked. The features responsible for the most importance are therefore desired, the AUC value is the percentile in which to keep features above. 0.5 keeps the highest ranked features responsible for 50 percent of the cumulative importance.}
}
\description{
A function that builds upon the blkbox function and performs k-fold cross validation and then provides votes for each fold as well as the importance of each feature in the models.
}
\author{
Zachary Davies, Boris Guennewig
}
\keyword{AUC,}
\keyword{Cross}
\keyword{Validation,}
\keyword{blkbox,}
\keyword{feature}
\keyword{k-fold,}
\keyword{selection,}

